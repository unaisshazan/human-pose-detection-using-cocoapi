{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.contrib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-a6aa28338257>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtf_pose\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimator\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTfPoseEstimator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtf_pose\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnetworks\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget_graph_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_wh\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\machine learning course\\tf-pose-estimation-master_2\\tf-pose-estimation-master\\tf_pose\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtf_pose\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrunner\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0minfer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mEstimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_estimator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\machine learning course\\tf-pose-estimation-master_2\\tf-pose-estimation-master\\tf_pose\\runner.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtf_pose\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcommon\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtf_pose\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0meval\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtf_pose\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimator\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTfPoseEstimator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtf_pose\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnetworks\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget_graph_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_wh\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\machine learning course\\tf-pose-estimation-master_2\\tf-pose-estimation-master\\tf_pose\\eval.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtf_pose\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommon\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mread_imgfile\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtf_pose\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimator\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTfPoseEstimator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtf_pose\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnetworks\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodel_wh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_graph_path\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\machine learning course\\tf-pose-estimation-master_2\\tf-pose-estimation-master\\tf_pose\\estimator.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtf_pose\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommon\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCocoPart\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtf_pose\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensblur\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msmoother\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSmoother\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensorrt\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtrt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.contrib'"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import time\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from tf_pose.estimator import TfPoseEstimator\n",
    "from tf_pose.networks import get_graph_path, model_wh\n",
    "\n",
    "logger = logging.getLogger('TfPoseEstimator-WebCam')\n",
    "logger.setLevel(logging.DEBUG)\n",
    "ch = logging.StreamHandler()\n",
    "ch.setLevel(logging.DEBUG)\n",
    "formatter = logging.Formatter('[%(asctime)s] [%(name)s] [%(levelname)s] %(message)s')\n",
    "ch.setFormatter(formatter)\n",
    "logger.addHandler(ch)\n",
    "\n",
    "fps_time = 0\n",
    "\n",
    "def str2bool(v):\n",
    "    return v.lower() in (\"yes\", \"true\", \"t\", \"1\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser(description='tf-pose-estimation realtime webcam')\n",
    "    parser.add_argument('--camera', type=int, default=0)\n",
    "\n",
    "    parser.add_argument('--resize', type=str, default='0x0',\n",
    "                        help='if provided, resize images before they are processed. default=0x0, Recommends : 432x368 or 656x368 or 1312x736 ')\n",
    "    parser.add_argument('--resize-out-ratio', type=float, default=4.0,\n",
    "                        help='if provided, resize heatmaps before they are post-processed. default=1.0')\n",
    "\n",
    "    parser.add_argument('--model', type=str, default='mobilenet_thin', help='cmu / mobilenet_thin / mobilenet_v2_large / mobilenet_v2_small')\n",
    "    parser.add_argument('--show-process', type=bool, default=False,\n",
    "                        help='for debug purpose, if enabled, speed for inference is dropped.')\n",
    "    \n",
    "    parser.add_argument('--tensorrt', type=str, default=\"False\",\n",
    "                        help='for tensorrt process.')\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    logger.debug('initialization %s : %s' % (args.model, get_graph_path(args.model)))\n",
    "    w, h = model_wh(args.resize)\n",
    "    if w > 0 and h > 0:\n",
    "        e = TfPoseEstimator(get_graph_path(args.model), target_size=(w, h), trt_bool=str2bool(args.tensorrt))\n",
    "    else:\n",
    "        e = TfPoseEstimator(get_graph_path(args.model), target_size=(432, 368), trt_bool=str2bool(args.tensorrt))\n",
    "    logger.debug('cam read+')\n",
    "    cam = cv2.VideoCapture(args.camera)\n",
    "    ret_val, image = cam.read()\n",
    "    logger.info('cam image=%dx%d' % (image.shape[1], image.shape[0]))\n",
    "\n",
    "    while True:\n",
    "        ret_val, image = cam.read()\n",
    "\n",
    "        logger.debug('image process+')\n",
    "        humans = e.inference(image, resize_to_default=(w > 0 and h > 0), upsample_size=args.resize_out_ratio)\n",
    "\n",
    "        logger.debug('postprocess+')\n",
    "        image = TfPoseEstimator.draw_humans(image, humans, imgcopy=False)\n",
    "\n",
    "        logger.debug('show+')\n",
    "        cv2.putText(image,\n",
    "                    \"FPS: %f\" % (1.0 / (time.time() - fps_time)),\n",
    "                    (10, 10),  cv2.FONT_HERSHEY_SIMPLEX, 0.5,\n",
    "                    (0, 255, 0), 2)\n",
    "        cv2.imshow('tf-pose-estimation result', image)\n",
    "        fps_time = time.time()\n",
    "        if cv2.waitKey(1) == 27:\n",
    "            break\n",
    "        logger.debug('finished+')\n",
    "\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
